%Este trabalho está licenciado sob a Licença Atribuição-CompartilhaIgual 4.0 Internacional Creative Commons. Para visualizar uma cópia desta licença, visite http://creativecommons.org/licenses/by-sa/4.0/deed.pt_BR ou mande uma carta para Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Computação paralela e distribuída (MPI)}\label{cap_mpi}
\thispagestyle{fancy}

Neste capítulo, vamos estudar aplicações da computação paralela em arquitetura de memória distribuída. Para tanto, vamos utilizar códigos C/C++ com a API \href{https://www.open-mpi.org/}{Open MPI}.

\section{Olá, Mundo!}\label{cap_mpi_sec_ola}

A computação paralela com MPI inicia-se simultaneamente com múltiplos processadores (instâncias de processamento), cada um utilizando seu próprio endereço de memória (memória distribuída). Cada processo lê e escreve em seu próprio endereço de memória privada. Observamos que o processamento já inicia-se ramificado e distribuído, sendo possível a comunicação entre os processos por instruções explícitas (instruções MPI, {\it Message Passing Interface}). A sincronização entre os processos também requer instruções específicas.

Vamos escrever nosso primeiro código MPI. O Código \verb+ola.cc+ é paralelamente executado por diferentes processadores, cada processo escreve ``Olá'' e identifica-se.

\lstinputlisting[title={Código: ola.cc}]{cap_mpi/dados/cc_ola/ola.cc}

Na linha 3, o API MPI é incluído no código. O ambiente MPI é inicializado na linha 8 com a rotina \href{https://www.open-mpi.org/doc/v4.1/man3/MPI\_Init.3.php}{MPI\_Init} inicializa o ambiente MPI. Na inicialização, o comunicador \verb+MPI_COMM_WORLD+ é construído entre todos os processos inicializados e um identificador ({\it rank}) é atribuído a cada processo. O número total de processos é obtido com a rotina \href{https://www.open-mpi.org/doc/v4.1/man3/MPI\_Comm\_size.3.php}{MPI\_Comm\_size}. Cada processo é identificado por um número natural sequencial 0, 1, ..., \verb+world_size+-1. O id ({\it rank}) de um processo é obtido com a rotina \href{https://www.open-mpi.org/doc/v4.1/man3/MPI\_Comm\_rank.3.php}{MPI\_Comm\_rank} (veja a linha 16). A rotina \href{https://www.open-mpi.org/doc/v4.1/man3/MPI\_Finalize.3.php}{MPI\_Finalize} finaliza o ambiente MPI.


Para compilar este código, digite no terminal
\begin{verbatim}
$ mpic++ ola.cc
\end{verbatim}
Esta instrução de compilação é análoga a
\begin{verbatim}
g++ ola.cc -I/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi -I/usr/lib/x86_64-linux-gnu/openmpi/include -pthread -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lmpi_cxx -lmpi
\end{verbatim}
ou semelhante dependendo da instalação. Para ver a sua configuração, digite
\begin{verbatim}
$ mpic++ ola.cc --showme
\end{verbatim}


Ao compilar, um executável \verb+a.out+ será criado. Para executá-lo, basta digitar no terminal:
\begin{verbatim}
$ mpirun -np 2 a.out
\end{verbatim}
Esta instrução inicializa simultaneamente duas cópias (\verb+-np 2+, dois processos) do código \verb+ola.cc+ (do executável \verb+a.out+). Cada processo é executado de forma idependente (em paralelo e não sincronizados).

Ao executar, devemos ver a saída do terminal como algo parecido com
\begin{verbatim}
Olá! Eu sou o processo 1/2.
Olá! Eu sou o processo 0/2.
\end{verbatim}

A saída irá variar conforme o processo que primeiro enviar a mensagem para o dispositivo de saída. Execute o código várias vezes e analise as saídas!

\subsection*{Exercícios resolvidos}

\begin{exeresol}
  O número de instâncias de processamento pode ser alterado diretamente na instrução \verb+mpirun+ pela opção \verb+-np+. Altere o número de instâncias de processamento para 4 e execute o Código ola.cc.
\end{exeresol}
\begin{resol}
  Para alterar o número de instâncias de processamento não é necessário recompilar o código\footnote{Caso ainda não tenha compilado o código, copile-o.}. Basta executá-lo com o comando
\begin{verbatim}
$ mpirun -np 4 ./a.out
\end{verbatim}
  A saída deve ser algo do tipo
\begin{verbatim}
Olá! Eu sou o processo 1/4.
Olá! Eu sou o processo 3/4.
Olá! Eu sou o processo 2/4.
Olá! Eu sou o processo 0/4.
\end{verbatim}
  Execute o código várias vezes e analise as saídas!
\end{resol}

\begin{exeresol}
  Escreva um código MPI para ser executado com 2 instâncias de processamento. Cada processo recebe os números inteiros
\begin{verbatim}
int n = 2;
int m = 3;
\end{verbatim}
Então, um dos processos deve escrever a soma $n+m$ e o outro deve escrever o produto.
\end{exeresol}
\begin{resol}
  O código abaixo contém uma implementação deste exercício. Veja os comentários abaixo.
  \lstinputlisting[title={Código: sp.cc}]{cap_mpi/dados/cc_exeresol_sp/sp.cc}

  Neste código, os processos são abortados caso o usuário tente executá-lo com um número de processos diferente de 2. Para abortar todos os processos ativos, utiliza-se a rotina \href{https://www.open-mpi.org/doc/v4.1/man3/MPI\_Abort.3.php}{MPI\_Abort} (veja as linhas 15-21). O argumento de entrada \verb+errorcode+ é arbitrário e serve para informar o usuário de uma categoria de erros conforme a política de programação utilizada.

  Observamos que o controle do que cada processo deve fazer, é feito através de sua identificação \verb+world_rank+ (veja as linhas 30-33).
\end{resol}

\subsection*{Exercícios}

\begin{exer}
  Rode o Código \verb+ola.cc+ com um número de processadores ({\it core}) maior do que o disponível em sua máquina. O que você observa? Modifique a instrução \verb+mpirun+ para aceitar a execução confirme o número de {\it threads} disponível na máquina. Por fim, modifique a instrução de forma a aceitar um número arbitrário de instâncias de processamento.
\end{exer}

\begin{exer}
  Faça um código MPI para ser executado com 2 instâncias de processamento. Uma das instâncias de processamento deve alocar
\begin{verbatim}
int a = 2;
int b = 3;
\end{verbatim}
e escrever a diferença $a-b$. A outra instância deve alocar
\begin{verbatim}
int a = 4;
int b = 5;
\end{verbatim}
e escrever o quociente $b/a$.
\end{exer}

\section {Rotinas de comunicação ponto-a-ponto}\label{cap_mpi_sec_p2pcom}

Em computação distribuída, rotinas de comunicação entre as instâncias de processamento são utilizadas para o compartilhamento de dados. Neste capítulo, vamos discutir sobre as rotinas de comunicação ponto-a-ponto, i.e. comunicações entre uma instância de processamento com outra.

\subsection {Envio e recebimento síncronos}

O envio e recebimento de dados entre duas instâncias de processamento pode ser feita com as rotinas \href{https://www.open-mpi.org/doc/current/man3/MPI\_Send.3.php}{MPI\_Send} e \href{https://www.open-mpi.org/doc/current/man3/MPI\_Recv.3.php}{MPI\_Recv}. A primeira é utilizada para o envio de um dado a partir de uma instância de processamento e a segunda é utilizada para o recebimento de um dado em uma instância de processamento.

A sintaxe da \href{https://www.open-mpi.org/doc/current/man3/MPI\_Send.3.php}{MPI\_Send} é
\begin{verbatim}
int MPI_Send(
  const void *buf, 
  int count, 
  MPI_Datatype datatype, 
  int dest,
  int tag, 
  MPI_Comm comm)
\end{verbatim}
e a sintaxe da \href{https://www.open-mpi.org/doc/current/man3/MPI\_Send.3.php}{MPI\_Recv} é
\begin{verbatim}
int MPI_Recv(
  void *buf, 
  int count, 
  MPI_Datatype datatype,
  int source, 
  int tag, 
  MPI_Comm comm, 
  MPI_Status *status)
\end{verbatim}

O primeiro argumento é o ponteiro do {\it buffer} de dados. No caso do \verb+MPI_Send+ é o ponteiro para a posição da memória do dado a ser enviado. No caso do \verb+MPI_Recv+ é o ponteiro para a posição da memória do dado a ser recebido. O segundo argunto \verb+count+ é o número de dados sequenciais a serem enviados. O argundo \verb+datatype+ é o tipo de dado. O MPI suporta os seguintes tipos de dados
\begin{verbatim}
MPI_SHORT               short int
MPI_INT                 int
MPI_LONG                long int
MPI_LONG_LONG           long long int
MPI_UNSIGNED_CHAR       unsigned char
MPI_UNSIGNED_SHORT      unsigned short int
MPI_UNSIGNED            unsigned int
MPI_UNSIGNED_LONG       unsigned long int
MPI_UNSIGNED_LONG_LONG  unsigned long long int
MPI_FLOAT               float
MPI_DOUBLE              double
MPI_LONG_DOUBLE         long double
MPI_BYTE                char
\end{verbatim}

Ainda sobre as sintaxes acima, o argumento \verb+source+ é o identificador {\it rank} da instância de processamento. O argunmento \verb+tag+ é um número arbitrário para identificar a operação de envio e recebimento. O argumento \verb+Comm+ especifica o comunicador (\verb+MPI_COMM_WORLD+ para aplicações básicas) e o último (somente para o \verb+MPI_Recv+) fornece informação sobre o {\it status} do recebimento do dado.

Vamos estudar o seguinte código abaixo.

\lstinputlisting[title={Código: sendRecv.cc}]{cap_mpi/dados/cc_sendRecv/sendRecv.cc}

O código acima pode rodado com pelo menos duas instâncias de processamento (veja as linhas 14-19). Nas linhas 28-29, o processo 0 envia o número \verb+3.1416+ (alocado na variável \verb+x+) para o processo 1. Nas linhas 32-33, o processo 1 recebe o número enviado pelo processo 0 e o aloca na variável \verb+y+.

{\bf Importante!} As rotinas \verb+MPI_Send+ e \verb+MPI_Recv+ provocam a sincronização entre os processos envolvidos. Por exemplo, no código acima, no que o processo 0 atinge a rotina \verb+MPI_Send+ ele ficará aguardando o processo 1 receber todos os dados enviados e só, então, irá seguir adiante no código. Analogamento, no que o processo 1 atingir a rotina \verb+MPI_Recv+, ele ficará aguardando o processo 0 enviar todos os dados e só, então, irá seguir adiante no código.

\subsection {Envio e recebimento assíncrono}

\emconstrucao

\subsection* {Exercícios resolvidos}

\emconstrucao

\subsection* {Exercícios}

\emconstrucao