%Este trabalho está licenciado sob a Licença Atribuição-CompartilhaIgual 4.0 Internacional Creative Commons. Para visualizar uma cópia desta licença, visite http://creativecommons.org/licenses/by-sa/4.0/deed.pt_BR ou mande uma carta para Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Problema de Valor Inicial}\label{cap_pvi}
\thispagestyle{fancy}

Neste capítulo, discutimos sobre \hl{técnicas numéricas para aproximar a solução de Equações Diferenciais Ordinárias com valor inicial (condição inicial)}, i.e. problemas da forma
\begin{subequations}\hleq
  \begin{align}
    \pmb{y}'(t) &= \pmb{f}(t,\pmb{y}(t)),\quad t>t_0,\\
    \pmb{y}(t_0) &= \pmb{y}_0,
  \end{align}
\end{subequations}
onde $\pmb{y}:t\in\mathbb{R}\mapsto\pmb{y}(t)\in\mathbb{R}^n$ é a função incógnita com dadas $\pmb{f}:(t,\pmb{y})\in\mathbb{R}\times\mathbb{R}^n\mapsto\pmb{f}(t,\pmb{y})\in\mathbb{R}^n$ e $\pmb{y}_0\in\mathbb{R}^n$, $n\geq 1$.

\section{Método de Euler}\label{cap_pvi_sec_euler}

Dado um \emph{problema de valor inicial}
\begin{subequations}\label{cap_pvi_sec_euler:eq:pvi}\hleq
  \begin{align}
    y'(t) &= f(t,y(t)),\quad t>t_0,\\
    y(t_0) &= y_0,
  \end{align}
\end{subequations}
temos que $f(t,y)$ é a derivada da solução $y(t)$ no tempo $t$. Então, aproximando a derivada pela \emph{razão fundamental} de passo $h>0$
\begin{equation}\hleq
  y'(t) \approx \frac{y(t+h)-y(t)}{h},
\end{equation}
obtemos
\begin{align}
  &\frac{y(t+h)-y(t)}{h} \approx f(t,y) \\
  &\hleq y(t+h) \approx y(t) + hf(t,y(t)).\label{cap_pvi_sec_euler:eq:euler_aux1}
\end{align}

Isto nos motiva a \hl{\emph{iteração do Método de Euler}}{\euler}
\begin{subequations}\hleq
  \begin{align}
    y^{(0)} &= y_0,\\
    y^{(k+1)} &= y^{(k)} + hf(t^{(k)},y^{(k)}),
  \end{align}
\end{subequations}
com $k=0, 1, 2, \dotsc, n$, $y^{(k)}\approx y\left(t^{(k)}\right)$, $t^{(k)} = t_0 + kh$ e \emph{passo} $h>0$.

\begin{ex}\label{cap_pvi_sec_euler:ex:euler_ex0}
  Consideramos o seguinte problema de valor inicial
  \begin{subequations}
    \begin{align}
      y' - y &= \sen(t), t>0\\
      y(0) &= \frac{1}{2}.
    \end{align}
  \end{subequations}
  Sua solução analítica é
  \begin{equation}
    y(t) = e^t - \frac{1}{2}\sen(t) - \frac{1}{2}\cos(t).
  \end{equation}

  Para computarmos a solução pelo Método de Euler, reescrevemos o problema da seguinte forma
  \begin{subequations}
    \begin{align}
      &y' = y + \sen(t), t>0\\
      &y(0) = \frac{1}{2},
    \end{align}
  \end{subequations}
  donde identificamos $f(t,y) := y + \sen(t)$, $t_0=0$ e $y_0=1/2$.

  \begin{table}[H]
    \centering
    \caption{Resultados obtidos para o problema do Exemplo \ref{cap_pvi_sec_euler:ex:euler_ex0} com $h=1\E-1$.}
    \begin{tabular}{l|cc|c}
      $k$ & $t^{(k)}$ &  $y^{(k)}$ & $y\left(t^{(k)}\right)$ \\\hline
      $0$ & $0.0$ & $5.00\E-1$ & $5.00\E-1$\\
      $1$ & $0.1$ & $5.50\E-1$ & $5.58\E-1$\\
      $2$ & $0.2$ & $6.15\E-1$ & $6.32\E-1$\\
      $3$ & $0.3$ & $6.96\E-1$ & $7.24\E-1$\\
      $4$ & $0.4$ & $7.96\E-1$ & $8.37\E-1$\\
      $5$ & $0.5$ & $9.14\E-1$ & $9.70\E-1$\\
      $6$ & $0.6$ & $1.05\E+0$ & $1.13\E+0$\\
      $7$ & $0.7$ & $1.22\E+0$ & $1.31\E+0$\\
      $8$ & $0.8$ & $1.40\E+0$ & $1.52\E+0$\\
      $9$ & $0.9$ & $1.61\E+0$ & $1.76\E+0$\\
      $10$ & $1.0$ & $1.85\E+0$ & $2.03\E+0$\\\hline
    \end{tabular}
  \end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./cap_pvi/dados/fig_euler_ex0/fig}
  \caption{Esboço das soluções numérica (pontos) e analítica (linha) para o problema do Exemplo~\ref{cap_pvi_sec_euler:ex:euler_ex0}.}
  \label{fig:ex_Euler_1}
\end{figure}
\end{ex}

\begin{lstlisting}[caption=euler.py, label=cap_pvi_sec_euler:cod:euler]
def euler(f, t0, y0, h, n):
    t = np.empty(n+1)
    t[0] = t0
    y = np.empty(n+1)
    y[0] = y0
    for k in range(n):
        t[k+1] = t[k] + h
        y[k+1] = y[k] + h*f(t[k], y[k])
    return t, y
\end{lstlisting}

\subsection{Análise Numérica}

O Método de Euler com passo $h$ aplicado ao problema de valor inicial \eqref{cap_pvi_sec_euler:eq:pvi}, pode ser escrito da seguinte forma
\begin{subequations}\label{cap_pvi_sec_euler:eq:mps}\hleq
  \begin{align}
    \tilde{y}(t^{(0)}; h) &= y_0,\\
    \tilde{y}(t^{(k+1)}; h) &= \tilde{y}(t^{(k)}; h) + h\Phi(t^{(k)}, \tilde{y}(t^{(k)}); h),
  \end{align}
\end{subequations}
onde $\tilde{y}(t^{(k)})$ representa a aproximação da solução exata $y$ no tempo $t^{(k)}=t_0+ kh$, $k=0, 1, 2, \ldots$. Métodos que podem ser escritos dessa forma, são chamados de \hl{\emph{Métodos de Passo Simples}} (ou único). No caso específico do método de Euler, temos
\begin{equation}\hleq
  \Phi(t, y; h) := f(t, y(t)).
\end{equation}

\subsubsection{Consistência}

Agora, considerando a solução exata $y$ de \eqref{cap_pvi_sec_euler:eq:pvi}, introduzimos
\begin{equation}\hleq
  \Delta(t, y; h) := \left\{
    \begin{array}{ll}
      \displaystyle\frac{y(t+h)-y(t)}{h} &, h\neq 0,\\
      f(t, y(t)) &, h=0.
    \end{array}\right.
\end{equation}

Com isso, vamos analisar o chamado \hl{\emph{erro de discretização local}}
\begin{equation}\hleq
  \tau(t, y; h) := \Delta(t, y; h) - \Phi(t, y; h),
\end{equation}
que \hl{estabelece uma medida quantitativa com que a solução exata $y(t)$ no tempo $t+h$ satisfaz a iteração do método de passo simples}.

\begin{defn}\normalfont{\hl{(Consistência.)}}\label{cap_pvi_sec_euler:defn:consistencia}
  Um \hl{método} de passo simples é dito ser \hl{consistente} quando
  \begin{equation}\hleq
    \lim_{h\to 0}\tau(t,y;h) = 0,
  \end{equation}
  ou, equivalentemente, quando
  \begin{equation}
    \lim_{h\to 0} \Phi(t, y; h) = f(t, y).
  \end{equation}
\end{defn}

\begin{obs}\normalfont{(Consistência do Método de Euler.)}
  Da Definição~\ref{cap_pvi_sec_euler:defn:consistencia}, temos que o \hl{Método de Euler é consistente}. De fato, temos
  \begin{align}
    \lim_{h\to 0} \tau(t, y; h) &= \lim_{h\to 0} \left(\Delta(t, y; h) - \Phi(t, y; h)\right)\\
                                &= \lim_{h\to 0} \left(\frac{y(t+h)-y(t)}{h} - f\left(t,y(t)\right)\right)\\
                                &= y'(t) - f\left(t, y(t)\right) = 0.
  \end{align}
\end{obs}

A \hl{\emph{ordem do erro de discretização local}} de um método de passo simples é dita ser $p$, quando
\begin{equation}\hleq
  \tau(t, y; h) = O(h^p),
\end{equation}
ou seja, quando
\begin{equation}
  \lim_{h\to 0} \frac{\tau(t, y; h)}{h^p} = C,
\end{equation}
para alguma constante $C$.

Para determinarmos a ordem do Método de Euler, tomamos a \hl{expansão em série de Taylor}{\taylor} da solução exata $y(t)$ em torno de $t$, i.e.
\begin{equation}\label{cap_pvi_sec_euler:eq:taylor}
  y(t+h) = y(t) + hy'(t) + \frac{h^2}{2}y''(t) + \frac{h^3}{6}y'''(t+\theta h),
\end{equation}
para algum $0<\theta<1$.
Como $y'(t)=f(t, y(t))$, temos
\begin{align}
  y''(t) &= \frac{d}{dt}f(t, y(t)) \\
         &= f_t(t, y) + f_y(t, y)y'\\
         &= f_t(t, y) + f_y(t, y)f(t, y).
\end{align}
Então, rearranjando os termos em \eqref{cap_pvi_sec_euler:eq:taylor}, obtemos
\begin{equation}\label{eq:pvi_delta_aux}
  \Delta(t, y; h) = f(t, y(t)) + \frac{h}{2}[f_t(t, y) + f_y(t, y)f(t, y)] + O(h^2).
\end{equation}
Portanto, para o método de Euler temos
\begin{align}
  \tau(t, y; h) &:= \Delta(t, y; h)-\Phi(t, y; h)\\
              &= \Delta(t, y; h) - f(t, y)\\
              &= \frac{h}{2}[f_t(t, y) + f_y(t, y)f(t, y)] + O(h^2)\\
              &= O(h).
\end{align}
Isto mostra que o \hl{Método de Euler é de ordem $1$}.

\subsubsection{Convergência}

A análise acima trata apenas da consistência do Método de Euler. Para analisarmos a \hl{convergência} de métodos de passo simples, definimos o \hl{\emph{erro de discretização global}}
\begin{equation}\hleq
  e(t; h_n) := \tilde{y}(t; h_n) - y(t),
\end{equation}
onde $\tilde{y}(t; h_n) \approx y(t)$ para $h_n := (t-t_0)/n$. Dizemos que o método é \hl{\emph{convergente}} quando
\begin{equation}\hleq
  \lim_{n\to \infty} e(t; h_n) = 0.
\end{equation}
Ainda, dizemos que o método tem \hl{erro de discretização global de ordem $p$} quando
\begin{equation}\hleq
  e(t; h_n) = O(h_n^p)
\end{equation}
para todo $t\in [t_0, t_f]$, $t_f > t_0$.

\begin{lema}\normalfont{(\cite[Cap. 7, Seção 7.2]{Stoer1993a})}\label{cap_pvi_sec_euler:lema:aux}
  Se a sequência $\left(\xi^{(k)}\right)_{k\in\mathbb{R}}$ satisfaz a estimativa
  \begin{equation}
    \left|\xi^{(k+1)}\right| \leq (1 + \delta)\left|\xi^{(k)}\right| + B,
  \end{equation}
  para dados $\delta > 0$ e $B\geq 0$, $k=0, 1, 2, \ldots$, então
  \begin{equation}
    \left|\xi^{(n)}\right| \leq e^{n\delta}\left|\xi^{(0)}\right| + \frac{e^{n\delta}-1}{\delta}B.
  \end{equation}
\end{lema}
\begin{dem}
  De forma iterativa, temos
  \begin{align}
    \left|\xi^{(1)}\right| &\leq (1 + \delta)\left|\xi^{(0)}\right| + B\\
    \left|\xi^{(2)}\right| &\leq (1 + \delta)\left|\xi^{(1)}\right| + B\\
                           &= (1+\delta)^2\left|\xi^{(0)}\right| + (1+\delta)B + B\\
                           &\vdots\\
    \left|\xi^{(k)}\right| &\leq (1 + \delta)^k\left|\xi^{(0)}\right| + B\sum_{k=0}^{k-1}(1+\delta)^k\\
                           &= (1 + \delta)^k\left|\xi^{(0)}\right| + B\frac{(1+\delta)^k-1}{\delta}.
  \end{align}
  Observando que $0<1+\delta\leq e^{\delta}$ para $\delta>-1$, concluímos que
  \begin{equation}
    \left|\xi^{(k)}\right| \leq e^{k\delta}\left|\xi^{(0)}\right| + \frac{e^{k\delta}-1}{\delta}B.
  \end{equation}
\end{dem}

\begin{teo}\normalfont{\hl{(Estimativa do Error Global.)}}\label{cap_pvi_sec_euler:teo:conv}
  Considere o PVI \eqref{cap_pvi_sec_euler:eq:pvi}, para $t_0 = a$, $y_0\in\mathbb{R}$. Suponha que $f$ é Lipschitz contínua em $y$
  \begin{equation}
    |f(t, y) - f(t, z)| \leq L|y - z|,
  \end{equation}
  para todo $(t,y)\in [a, b]\times\mathbb{R}$ e que exista $M>0$ tal que
  \begin{equation}
    |y''(t)| \leq M,
  \end{equation}
  para todo $t\in [a, b]$. Então, as iteradas do Método de Euler $y^{(k)} \approx y\left(t^{(k)}\right)$, $t^{(k)} = t_0 + kh$, $h > (b-a)/n$, $k=0, 1, 2, \dotsc, n+1$, satisfazem a seguinte \hl{\emph{estimativa do erro de discretização global}}
  \begin{equation}\label{cap_pvi_sec_euler:eq:est_errg}\hleq
    \left|y^{(k)} - y\left(t^{(k)}\right)\right| \leq \frac{hM}{2L}\left[e^{L\left(t^{(k)}-t_0\right)}-1\right].
  \end{equation}
\end{teo}
\begin{dem}
  Para $k=0$ o resultado é imediato. Agora, usamos o polinômio de Taylor
  \begin{equation}
    y\left(t^{(k+1)}\right) = y\left(t^{(k)}\right) + hf\left(t^{(k)}, y\left(t^{(k)}\right)\right) + \frac{h^2}{2}y''\left(\xi^{(k)}\right),
  \end{equation}
  onde $t^{(k)} \leq \xi^{(k)} \leq t^{(k+1)}$, $k=0, 1, 2, \ldots, n$. Já, as iteradas de Euler são
  \begin{equation}
    y^{(k+1)} = y^{(k)} + hf\left(t^{(k)}, y^{(k)}\right).
  \end{equation}
  Subtraindo esses equações, obtemos
  \begin{equation}
    \begin{aligned}
      y^{(k+1)} - y\left(t^{(k+1)}\right) &= y^{(k)} - y\left(t^{(k)}\right) \\
      &+ h\left[f\left(t^{(k)}, y^{(k)}\right) - f\left(t^{(k)}, y\left(t^{(k)}\right)\right)\right] - \frac{h^2}{2}y''\left(\xi^{(k)}\right)
    \end{aligned}
  \end{equation}
  Da hipótese de $f$ Lipschitz, temos
  \begin{equation}
    \begin{aligned}
      \left|y^{(k+1)} - y\left(t^{(k+1)}\right)\right| &\leq \left|y^{(k)} - y\left(t^{(k)}\right)\right| \\
      &+ hL\left|y^{(k)} - y\left(t^{(k)}\right)\right| + \frac{h^2}{2}\left|y''\left(\xi^{(k)}\right)\right|
    \end{aligned}
  \end{equation}
  Ou, ainda,
  \begin{equation}
    \left|y^{(k+1)} - y\left(t^{(k+1)}\right)\right| \leq (1 + hL)\left|y^{(k+1)} - y\left(t^{(k+1)}\right)\right| + \frac{h^2M}{2}.
  \end{equation}
  Do Lema \ref{cap_pvi_sec_euler:lema:aux}, temos
  \begin{equation}
    \left|y^{(k+1)} - y\left(t^{(k+1)}\right)\right| \leq \frac{h^2M}{2}\frac{e^{khL}-1}{hL},
  \end{equation}
  donde segue a estimativa do erro global \eqref{cap_pvi_sec_euler:eq:est_errg}.
\end{dem}

\begin{obs}\normalfont{\hl{(Convergência.)}}
  Do Teorema \ref{cap_pvi_sec_euler:teo:conv}, \hl{a ordem do erro de discretização global de um método de passo simples é igual a sua ordem do erro de discretização local}. Portanto, o \hl{Método de Euler é convergente e é de ordem $1$}.
\end{obs}

\begin{ex}\label{cap_pvi_sec_euler:ex:conv}
  Consideremos o seguinte problema de valor inicial
  \begin{subequations}
    \begin{align}
      &y' = y + 1, t>0\\
      &y(0) = 0.
    \end{align}
\end{subequations}
  Na Tabela~\ref{cap_pvi_sec_euler:tab:euler_conv}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo Método de Euler com diferentes passos $h$. A solução analítica deste problema é $y(t) = e^{t}-1$.
 
  \begin{table}[h!]
    \centering
    \caption{Resultados referentes ao Exemplo~\ref{cap_pvi_sec_euler:ex:conv}.}
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $1.59374$ & $1.2\E-1$ \\
      $10^{-2}$ & $1.70481$ & $1.3\E-2$ \\
      $10^{-3}$ & $1.71692$ & $1.4\E-3$ \\
      $10^{-5}$ & $1.71827$ & $1.4\E-5$ \\
      $10^{-7}$ & $1.71828$ & $1.4\E-7$ \\
      $10^{-9}$ & $1.71828$ & $1.4\E-9$ \\\hline
    \end{tabular}
    \label{cap_pvi_sec_euler:tab:euler_conv}
  \end{table}
\end{ex}

\subsubsection{Erros de Arredondamento}

O Teorema \ref{cap_pvi_sec_euler:teo:conv} não leva em consideração os erros de arredondamento. Levando em conta esses erros, a iteração do método de Euler tem a forma
\begin{subequations}\label{cap_pvi_sec_euler:eq:euler_errarr}
  \begin{align}
    &\tilde{y}^{(0)} = y_0 + \delta^{(k)},\\
    &\tilde{y}^{(k+1)} = \tilde{y}^{(k)} + hf\left(t^{(k)}, \tilde{y}^{(k)}\right) + \delta^{(k+1)},
  \end{align}
\end{subequations}
onde $\delta^{(k)}$ é o erro devido a arredondamentos na $k$-ésima iterada, $t^{(k)} = t_0 + hk$, $k=0, 1, 2, \dotsc, n$. Assumindo as hipóteses do Teorema \ref{cap_pvi_sec_euler:teo:conv}, podemos mostrar a seguinte estimativa de erro global
\begin{equation}\label{cap_pvi_sec_euler:eq:euler_errarr_est}\hleq
  \begin{aligned}
    \left|\tilde{y}^{(k+1)} - y\left(t^{(k+1)}\right)\right| &\leq \frac{1}{L}\left(\frac{hM}{2} + \frac{\delta}{h}\right)\left[e^{L\left(t^{(k)}-t_0\right)}-1\right]\\
    &+ |\delta_0|e^{L\left(t^{(k)}-t_0\right)},
\end{aligned}
\end{equation}
para $\delta^{(k)} < \delta$, $k=0, 1, 2, \dotsc, n$.

\subsection{Exercícios}

\begin{exer}
  O problema de valor inicial
  \begin{subequations}
    \begin{align}
      &y' = \pi\left[\cos^2(\pi t) - \sen^2(\pi t)\right],\quad t>0\\
      &y(0) = 0.
    \end{align}
  \end{subequations}
  tem solução analítica $y(t) = \sen(\pi t)\cos(\pi t)$. Compute a aproximação $\tilde{y}(1) \approx y(1)$ pelo Método de Euler com passo $h=10^{-1}$ e forneça o erro $e(1, h) := \tilde{y}(1, h) - y(1)$.
\end{exer}
\begin{resp}
  $\tilde{y}(1.5) = 3.14159\E-1$, $e(1, h) = 3.1E-01$
\end{resp}

\begin{exer}
  Use o Método de Euler para computar a solução de
  \begin{subequations}
    \begin{align}
      &y' = e^{2t} - 2y,\quad 0 < t\leq 1,\\
      &y(0) = 0.
    \end{align}
  \end{subequations}
  Escolha um passo $h$ adequado de forma que $y(1)$ seja computado com precisão de $5$ dígitos significativos.
\end{exer}
\begin{resp}
  $h=10^{-6}$, $\tilde{y}(1) = 1.8134\E+0$
\end{resp}

\begin{exer}
  Considere o seguinte problema de valor inicial
  \begin{subequations}
    \begin{align}
      &y' + e^{-y^2+1} = 2,\quad t>1,\\
      &y(1) = -1.
    \end{align}
\end{subequations}
Use o método de Euler para computar o valor aproximado de $y(2)$ com precisão de $6$ dígitos significativos.
\end{exer}
\begin{resp}
  $-5.58858\E-1$
\end{resp}

\begin{exer}
  Use o Método de Euler para computar a solução de
  \begin{subequations}
    \begin{align}
      &y' = -30y,\quad 0 < t\leq 1,\\
      &y(0) = \frac{1}{3}
    \end{align}
  \end{subequations}
  A solução analítica é $y(t) = \frac{1}{3}e^{-30t}$. Compute a solução aproximação $\tilde{y}(1)$ e o erro $|\tilde{y}(1) - y(1)|$ usando o passo $h=10^{-1}$. O erro obtido está de acordo com a estimativa \eqref{cap_pvi_sec_euler:eq:est_errg}?
\end{exer}
\begin{resp}
  $|\tilde{y}(1) - y(1)| = 3.4\E+2$. Dica: verifique as hipóteses do Teorema \ref{cap_pvi_sec_euler:teo:conv}.
\end{resp}

\subsubsection{Análise Numérica}

\begin{exer}
  Mostre que se $\delta>-1$, então $0 < 1+\delta \leq e^{\delta}$.
\end{exer}
\begin{resp}
  Dica: use o polinômio de Taylor de grau 2 de $e^\delta$.
\end{resp}

\begin{exer}
  Seja dado um PVI \eqref{cap_pvi_sec_euler:eq:pvi}, $t_0\leq t \leq t_f$. Sejam $\tilde{y}^{(k)}$, $k=0, 1, 2, \dotsc, n$, as aproximações computadas conforme em \eqref{cap_pvi_sec_euler:eq:euler_errarr}, com $\delta^{(k)} < \delta$. Assumindo as mesmas hipóteses do Teorema \ref{cap_pvi_sec_euler:teo:conv}, mostre a estimativa de erro global \eqref{cap_pvi_sec_euler:eq:euler_errarr_est}.
\end{exer}
\begin{resp}
  Dica: estude a demonstração do Teorema \ref{cap_pvi_sec_euler:teo:conv}.
\end{resp}

\begin{exer}
  Assumindo um erro de arredondamento máximo de $\delta > 0$, use \eqref{cap_pvi_sec_euler:eq:euler_errarr_est} para obter uma estimativa para a melhor escolha de $h$.
\end{exer}
\begin{resp}
  $h = \sqrt{2\delta/M}$. Dica: Encontre o mínimo de $E(h) := M/2 + \delta/h^2$.
\end{resp}

\section{Métodos de Taylor de Alta Ordem}\label{cap_pvi_sec_taylor}

Métodos de Taylor{\taylor} são usados para computar a solução numérica de Problemas de Valor Inicial (PVI) da forma
\begin{subequations}\label{cap_pvi_sec_taylor:eq:pvi}
  \begin{align}
    &y' = f(t, y),\quad t_0 < t \leq t_f,\\
    &y(t_0) = y_0,
  \end{align}
\end{subequations}
onde $y:[t_0, t_f]\mapsto \mathbb{R}$ é a função incógnita, dada $f:[t_0, t_f]\times\mathbb{R}\to\mathbb{R}$ e dado valor inicial $y_0\in\mathbb{R}$.

Na Seção \ref{cap_pvi_sec_euler}, vimos que \hl{a ordem do erro de discretização local} do Método de Euler{\euler} \hl{é também a do erro de discretização global}. Este resultado é generalizado pelo Teorema \ref{cap_pvi_sec_taylor:teo:conv}, \hl{para todo o método de passo simples}
\begin{subequations}\label{cap_pvi_sec_taylor:eq:iterps}
  \begin{align}
    &y^{(0)} = y_0,\\
    &y^{(k+1)} = y^{(k)} + h\Phi\left(t^{(k)}, y^{(k)}\right),
  \end{align}
\end{subequations}
onde $y^{(k)}\approx y\left(t^{(k)}\right)$, $t^{(k)} = t_0 + kh$, $h = (t_f-t_0)/n$, $k = 0, 1, 2, \dotsc, n$.

Antes, lembramos que o \hl{\emph{erro de discretização local}} é definido por
\begin{equation}\hleq
  \tau(t, y; h) := \delta(t, y; h) - \Phi(t, y; h),
\end{equation}
onde
\begin{equation}\hleq
  \Delta(t, y; h) := \left\{
    \begin{array}{ll}
      \displaystyle\frac{y(t+h) - y(t)}{h} &, h\neq 0,\\
      f\left(t, y(t)\right) &, h=0.
    \end{array}
  \right.
\end{equation}

Já, o \hl{\emph{erro de discretização global}} é definido por
\begin{equation}\hleq
  e(t; h_n) := \tilde{y}(t; h_n) - y(t),
\end{equation}
onde $\tilde{y}(t; h_n) \approx y(t)$ dada por \eqref{cap_pvi_sec_taylor:eq:iterps} para $h_n = (t-t_0)/n$.

Com o objetivo de desenvolvermos métodos de alta ordem, podemos usar o polinômio de Taylor de ordem $m$ de $y=y(t)$
\begin{equation}
  \begin{aligned}
    y\left(t^{(k+1)}\right) &= y\left(t^{(k)}\right) + hy'\left(t^{(k)}\right) + \frac{h^2}{2}y''\left(t^{(k)}\right)\\
    &+ \cdots + \frac{h^m}{m!}\frac{d^m y}{d t^m}\left(t^{(k)}\right) + \frac{h^{m+1}}{(m+1)!}\frac{d^{m+1} y}{d t^{m+1}}\left(\xi^{(k)}\right),
  \end{aligned}
\end{equation}
donde
\begin{equation}
  \begin{aligned}
    y\left(t^{(k+1)}\right) &= y\left(t^{(k)}\right) + hf\left(t^{(k)}, y^{(k)}\right) + \frac{h^2}{2}f'\left(t^{(k)}, y^{(k)}\right) \\
    &+ \cdots + \frac{h^m}{m!}\frac{d^{m-1} f}{d t^{m-1}}\left(t^{(k)}, y^{(k)}\right) + \frac{h^{m+1}}{(m+1)!}\frac{d^{m} f}{d t^{m}}\left(\xi^{(k)}, y\left(\xi^{(k)}\right)\right).
  \end{aligned}
\end{equation}

Isto nos motiva a \hl{\emph{iteração do Método de Taylor de Ordem $m$}}:
\begin{subequations}\hleq
  \begin{align}
    &y^{(0)} = y_0,\\
    &y^{(k+1)} = y^{(k)} + hT^{(m)}\left(t^{(k)}, y^{(k)}\right),
  \end{align}  
\end{subequations}
onde
\begin{equation}\hleq
  \begin{aligned}
    T^{(m)}\left(t^{(k)}, y^{(k)}\right) &:= f\left(t^{(k)}, y^{(k)}\right) + \frac{h}{2}f'\left(t^{(k)}, y^{(k)}\right)\\
    &+ \cdots + \frac{h^{m-1}}{m!}\frac{d^{m-1} f}{d t^{m-1}}\left(t^{(k)}, y^{(k)}\right)
\end{aligned}
\end{equation}

\begin{ex}
  Considere o PVI
  \begin{subequations}
    \begin{align}
      &y' = y + \sen(t),\quad 0 < t \leq 1,\\
      &y(0) = \frac{1}{2}.
    \end{align}
  \end{subequations}
  Vamos usar o Método de Taylor de Ordem 2 para computar sua solução e comparar com a solução analítica
  \begin{equation}
    y(t) = e^t - \frac{1}{2}\sen(t) - \frac{1}{2}\cos(t).
  \end{equation}

  \begin{center}
    \begin{tabular}[H]{ll}
      $h$ & $\left|\tilde{y}(1) - y(1)\right|$\\\hline
      $10^{-1}$ & $4.9\E-3$ \\
      $10^{-2}$ & $5.2\E-5$ \\
      $10^{-3}$ & $5.2\E-7$ \\
      $10^{-4}$ & $5.2\E-9$ \\
      $10^{-5}$ & $5.2\E-11$ \\\hline
    \end{tabular}
  \end{center}

\begin{lstlisting}[caption=taylor.py, label=cap_pvi_sec_taylor:cod:taylor.py]
import numpy as np

def taylor(Phi, t0, y0, h, n):
    t = t0
    y = y0
    for k in range(n):
        y += h*Phi(t, y, h)
        t += h
    return t, y

def f(t, y):
    return y + np.sin(t)

def fl(t, y):
    return f(t, y) + np.cos(t)

def Phi(t, y, h):
    return f(t, y) + h/2*fl(t, y)

# analítica
def exata(t):
    return np.exp(t) - 0.5*np.sin(t) - 0.5*np.cos(t)

h = 1e-1
n = round(1/h)
t,y = taylor(Phi, 0., 0.5, h, n)
\end{lstlisting}
\end{ex}

\subsection{Análise Numérica}

\begin{teo}\normalfont{(\hl{Convergência}, \cite[Cap. 7, Seção 7.2]{Stoer1993a}.)}\label{cap_pvi_sec_taylor:teo:conv}
  Considere o PVI \eqref{cap_pvi_sec_taylor:eq:pvi}, para $t_0\in [a, b]$ e $y_0\in\mathbb{R}$. Seja $\Phi$ contínua em
  \begin{equation}
    G := \{(t, y, h): a\leq t\leq b, |y-y(t)|\leq\gamma, 0\leq|h|\leq h_0\},
  \end{equation}
  para $h_0>0$ e $\gamma>0$. Sejam também, $M, N$ constantes tais que
  \begin{equation}
    \left|\Phi(t, y; h) - \Phi(t, z; h)\right| \leq M|y - z|,
  \end{equation}
  para todas $(t, y; h), (t, z; h)\in G$. Se, ainda, para algum $p>0$ e para todo $t\in [a, b]$, $|h|\leq h_0$, temos a \hl{\emph{estimativa do erro de discretização local}}
  \begin{equation}\hleq
    \left|\tau(t, y(t); h)\right| \leq N |h|^p,
  \end{equation}
  então existe $\overline{h}$, $0<\overline{h}<h_0$, tal que vale a seguinte \hl{\emph{estimativa do erro de discretização global}}
  \begin{equation}\hleq
    |e(t; h_n)| \leq |h_n|^pN\frac{e^{M|t-t_0|}-1}{M},
  \end{equation}
  para todo $t\in [a, b]$ e para todo $h_n = (t-t_0)/n$, $n=1, 2, \ldots$, com $|h_n|\leq \overline{h}$.
\end{teo}
\begin{dem}
  Seja
  \begin{equation}
    \tilde{\Phi}(t, y; h) := \left\{
      \begin{array}{ll}
        \Phi(t, y; h) &, (t, y, h)\in G,\\
        \Phi(t, y(t)+\gamma; h) &, t\in [a, b], |h|\leq h_0, y\geq y(t)+\gamma,\\
        \Phi(t, y(t)-\gamma; h) &, t\in [a, b], |h|\leq h_0, y\leq y(t)-\gamma,
      \end{array}
    \right.
  \end{equation}
  A função $\tilde{\Phi}$ é contínua em
  \begin{equation}
    \tilde{G} := \{(t, y; h): t\in [a, b], y\in\mathbb{R}, |h|\geq h_0\}
  \end{equation}
  e satisfaz
  \begin{equation}\label{cap_pvi_sec_taylor:eq:aux0}
    \left|\tilde{\Phi}(t, y; h) - \tilde{\Phi}(t, z; h)\right| \leq M|y - z|,
  \end{equation}
  para todas $(t, y; h), (t, z; h)\in \tilde{G}$. Ainda, como $\tilde{\Phi}(t, y(t); h) = \Phi(t, y(t); h)$, também temos que
  \begin{equation}\label{cap_pvi_sec_taylor:eq:aux1}
    |\Delta(t, y(t); h) - \tilde{\Phi}(t, y(t); h)| \leq N |h|^p,
  \end{equation}
  para $t\in [a, b]$ e $|h|\leq h_0$.

  Sejam, $\tilde{y}^{(k)} := \tilde{y}\left(t^{(k)}; h\right)$, $t^{(k)} = t_0 + kh$, $\tilde{y}^{(0)} = y_0$:
  \begin{align}
    \tilde{y}^{(k+1)} = \tilde{y}^{(k)} + h\tilde{\Phi}\left(t^{(k)}, \tilde{y}^{(k)}; h\right),
    y\left(t^{(k+1)}\right) = y\left(t^{(k)}\right) + h\Delta\left(t^{(k)}, y\left(t^{(k)}\right); h\right).
  \end{align}
  Definindo $\tilde{e}^{(k)} := \tilde{y}^{(k)} - y\left(t^{(k)}\right)$, obtemos a fórmula de recorrência
  \begin{align}
    \tilde{e}^{(k+1)} &= \tilde{e}^{(k)} + h\left[\tilde{\Phi}\left(t^{(k)}, \tilde{y}^{(k)}; h\right) - \Delta\left(t^{(k)}, y\left(t^{(k)}\right); h\right)\right]\\
                      &= \tilde{e}^{(k)} + h\left[\tilde{\Phi}\left(t^{(k)}, \tilde{y}^{(k)}; h\right) - \tilde{\Phi}\left(t^{(k)}, y\left(t^{(k)}\right); h\right)\right]\\
                      &+ h\left[\tilde{\Phi}\left(t^{(k)}, y\left(t^{(k)}\right); h\right) - \Delta\left(t^{(k)}, y\left(t^{(k)}\right); h\right)\right].\label{cap_pvi_sec_taylor:eq:aux2}
  \end{align}
  Agora, de \eqref{cap_pvi_sec_taylor:eq:aux0} e \eqref{cap_pvi_sec_taylor:eq:aux1}, temos
  \begin{align}
    &\left|\tilde{\Phi}\left(t^{(k)}, \tilde{y}^{(k)}; h\right) - \tilde{\Phi}\left(t^{(k)}, y\left(t^{(k)}\right); h\right)\right| \leq M\left|\tilde{e}^{(k)}\right|\\
    &\left|\Delta\left(t^{(k)}, y\left(t^{(k)}\right); h\right) - \tilde{\Phi}\left(t^{(k)}, y\left(t^{(k)}\right); h\right)\right| \leq N |h|^p
  \end{align}
  Portanto, de \eqref{cap_pvi_sec_taylor:eq:aux2}, temos
  \begin{equation}
    \left|\tilde{e}^{(k+1)}\right| \leq \left(1 + |h|M\right)\left|\tilde{e}^{(k)}\right| + N |h|^{p+1}
  \end{equation}
  Então, do Lema \ref{cap_pvi_sec_euler:lema:aux}, temos
  \begin{equation}\label{cap_pvi_sec_taylor:eq:aux3}
    \left|\tilde{e}^{(k)}\right| \leq N|h|^p\frac{e^{k|h|M}-1}{M}.
  \end{equation}
  Sejam, agora, $t\in [a, b]$, $t\neq t_0$ fixo e $h := h_n = (t-t_0)/n$, $n>0$. Então, $t^{(n)} = t_0 + nh = t$ e de \eqref{cap_pvi_sec_taylor:eq:aux3} temos
  \begin{equation}
    \left|\tilde{e}\left(t, h_n\right)\right| \leq N|h_n|^p\frac{e^{M|t-t_0|}-1}{M},
  \end{equation}
  para todo $t\in [a, b]$, $|h_n|\leq h_0$. Uma vez que $|t-t_0|\leq |b-a|$ e $\gamma >0$, existe $\overline{h}$, $0<\overline{h}\leq h_0$, tal que $\left|\tilde{e}\left(t, h_n\right)\right| \leq \gamma$ para todo $t\in [a, b]$ e $|h_n|\leq \overline{h}$. Logo, para o método de passo simples \eqref{cap_pvi_sec_taylor:eq:iterps} gerado por $\Phi$, temos para $|h|\leq\overline{h}$ que
  \begin{align}
    &\tilde{y}^{(k)} = y^{(k)},\\
    &\tilde{e}^{(k)} = e^{(k)},\\
    &\tilde{\Phi}\left(t^{(k)}, \tilde{y}^{(k)}; h\right) = \Phi\left(t^{(k)}, \tilde{y}^{(k)}; h\right).
  \end{align}
  Concluímos que
  \begin{equation}
    \left|e\left(t, h_n\right)\right| \leq N|h_n|^p\frac{e^{M|t-t_0|}-1}{M},
  \end{equation}
  para todo $t\in [a, b]$ e $h_n = (t-t_0)/n$, $n=1, 2, \ldots$, com $|h_n|\leq \overline{h}$.
\end{dem}

\subsection{Exercícios}

[[tag:construcao]]


\section{Métodos de Runge-Kutta}\label{cap_pvi_sec_RK}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Os métodos de Runge-Kutta de $s$-estágios são métodos de passo simples da seguinte forma
\begin{equation}
  y^{(i+1)} = y^{(i)} + h(c_1k_1 + \cdots + c_sk_s)
\end{equation}
onde
\begin{align}
  k_1 &:= f(t^{(i)},y^{(i)}),\\
  k_2 &:= f(t^{(i)}+\alpha_2h,y^{(i)}+h\beta_{21}k_1),\\
  k_3 &:= f(t^{(i)}+\alpha_3h,y^{(i)}+h(\beta_{31}k_1+\beta_{32}k_2)),\\
      &~~\vdots\\
  k_s &:= f(t^{(i)}+\alpha_sh,y^{(i)}+h(\beta_{s1}k_1+\cdots+\beta_{s,s-1}k_{s-1})),
\end{align}
$t^{(i)}=t_0+(i-1)h$ e $y^{(1)}=y_0$.

Na sequência, discutimos alguns dos métodos de Runge-Kutta usualmente utilizados. Pode-se encontrar uma lista mais completa em~\cite[Cap. 8, Seç. 3.2]{Isaacson1994a}.

\subsection{Métodos de Runge-Kutta de ordem 2}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Precisamos apenas de $2$ estágios para obtermos métodos de Runge-Kutta de ordem 2. Portanto, assumimos
\begin{align}
  y^{(i+1)} = y^{(i)} &+ h\left[c_1f(t^{(i)},y^{(i)}) \right.\nonumber\\
  &\left. + c_2f(t^{(i)}+\alpha_2h,y^{(i)}+h\beta_{21}f(t^{(i)},y^{(i)}))\right].\label{eq:rk_2_aux}
\end{align}
Neste caso, o erro de discretização local é dado por
\begin{equation}
  \tau(t,y;h) = \Delta(t,y;h) - \Phi(t,y;h),
\end{equation}
onde, da equação~\eqref{eq:pvi_delta_aux} temos
\begin{equation}\label{eq:pvi_delta_aux2}
  \Delta(t,y;h) = f(t,y(t)) + \frac{h}{2}[f_t(t,y) + f_y(t,y)f(t,y)] + O(h^2)
\end{equation}
e de~\eqref{eq:rk_2_aux}
\begin{equation}
  \Phi(t,y;h) = c_1f(t,y) + c_2f(t+\alpha_2h,y+h\beta_{21}f(t,y))
\end{equation}
Agora, tomando a expansão de série de Taylor em torno de $t$ de $\Phi(t,y;h)$, temos
\begin{align}\label{eq:pvi_phi_aux2}
  \Phi(t,y;h) = (c_1+c_2)f(t,y) &+ c_2h[\alpha_2f_t(t,y) \nonumber\\
  &+\beta_{21}f_y(t,y)f(t,y)) + O(h^2).
\end{align}
Então, por comparação de \eqref{eq:pvi_delta_aux2} e \eqref{eq:pvi_phi_aux2}, temos
\begin{align}
  c_1&+c_2 = 1\\
  c_2&\alpha_2 = \frac{1}{2}\\
  c_2&\beta_{21} = \frac{1}{2}.
\end{align}
Assim sendo, temos mais de uma solução possível.

\subsubsection{Método do ponto médio}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

O método do ponto médio é um método de Runge-Kutta de ordem $2$ proveniente da escolha de coeficientes
\begin{equation}
  c_1 = 0, \quad c_2 = 1, \quad \alpha_2 = \frac{1}{2},\quad \beta_{21}=\frac{1}{2}.
\end{equation}
Logo, a iteração do método do ponto médio é
\begin{align}
  y^{(1)} &= y_0\\
  y^{(i+1)} &= y^{(i)} + hf\left(t^{(i)}+\frac{h}{2},y^{(i)}+\frac{h}{2}f(t^{(i)},y^{(i)})\right).
\end{align}

\begin{ex}\label{ex:ponto_medio_1}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_ponto_medio_1}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método do ponto médio com diferentes passos $h$.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,02175$ & $5,6\E-03$ \\
      $10^{-2}$ & $2,02733$ & $6,0\E-05$ \\
      $10^{-3}$ & $2,02739$ & $6,1\E-07$ \\
      $10^{-4}$ & $2,02740$ & $6,1\E-09$ \\
      $10^{-5}$ & $2,02737$ & $2,9\E-05$ \\\hline
    \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:ponto_medio_1}.}
    \label{tab:ex_ponto_medio_1}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_ponto_medio_1} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-1;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% t(1)=0;
% y(1)=0.5;

% for i=1:n-1
%   t(i+1) = t(i)+h;
%   y(i+1)=y(i)+h*f(t(i)+h/2,y(i)+h/2*f(t(i),y(i)));
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%1.5E %1.1E\n",y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsubsection{Método de Euler modificado}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

O método de Euler modificado é um método de Runge-Kutta de ordem $2$ proveniente da escolha de coeficientes
\begin{equation}
  c_1 = \frac{1}{2}, \quad c_2 = \frac{1}{2}, \quad \alpha_2 = 1,\quad \beta_{21}=1.
\end{equation}
Logo, a iteração do método de Euler modificado é
\begin{align}
  y^{(1)} &= y_0\\
  y^{(i+1)} &= y^{(i)} + \frac{h}{2}\left[f(t^{(i)},y^{(i)}) + f(t^{(i)}+h,y^{(i)}+hf(t^{(i)},y^{(i)})\right].
\end{align}

\begin{ex}\label{ex:Euler_modificado_1}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_Euler_modificado_1}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método de Euler modificado com diferentes passos $h$.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,02096$ & $6,4\E-03$ \\
      $10^{-2}$ & $2,02733$ & $6,9\E-05$ \\
      $10^{-3}$ & $2,02739$ & $6,9\E-07$ \\
      $10^{-4}$ & $2,02740$ & $6,9\E-09$ \\
      $10^{-5}$ & $2.02737$ & $2,9\E-05$ \\\hline
    \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:Euler_modificado_1}}
    \label{tab:ex_Euler_modificado_1}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_Euler_modificado_1} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-1;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% t(1)=0;
% y(1)=0.5;

% for i=1:n-1
%   t(i+1) = t(i)+h;
%   y(i+1)=y(i)+h*f(t(i),y(i));
%   y(i+1)=y(i)+h/2*(f(t(i),y(i))+f(t(i+1),y(i+1)));
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%1.5E %1.1E\n",y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsection{Método de Runge-Kutta de ordem $4$}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Um dos métodos de Runge-Kutta mais empregados é o seguinte método de ordem $4$:
\begin{equation}
  y^{(i+1)} = y^{(i)} + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4),
\end{equation}
onde
\begin{align}
  k_1 &:= f(t^{(i)},y^{(i)}),\\
  k_2 &:= f(t^{(i)}+h/2,y^{(i)}+hk_1/2),\\
  k_3 &:= f(t^{(i)}+h/2,y^{(i)}+hk_2/2),\\
  k_4 &:= f(t^{(i)}+h,y^{(i)}+hk_3),
\end{align}
$t^{(i)}=t_0+(i-1)h$ e $y^{(1)}=y_0$.

\begin{ex}\label{ex:RK4_1}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_RK4_1}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método de Runge-Kutta de quarta ordem com diferentes passos $h$.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,02739$ & $2,8\E-06$ \\
      $10^{-2}$ & $2,02740$ & $3,1\E-10$ \\
      $10^{-3}$ & $2,02740$ & $3,0\E-14$ \\
      $10^{-4}$ & $2,02740$ & $4,4\E-14$ \\\hline
    \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:RK4_1}}
    \label{tab:ex_RK4_1}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_RK4_1} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-4;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% t(1)=0;
% y(1)=0.5;

% for i=1:n-1
%   t(i+1) = t(i)+h;
%   k1 = h*f(t(i),y(i));
%   k2 = h*f(t(i)+h/2,y(i)+k1/2);
%   k3 = h*f(t(i)+h/2,y(i)+k2/2);
%   k4 = h*f(t(i)+h,y(i)+k3);
%   y(i+1)=y(i)+(k1+2*k2+2*k3+k4)/6;
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%1.5E %1.1E\n",y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsection{Exercícios}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

\begin{exer}
  Considere o seguinte problema de valor inicial
  \begin{align}
    y' &+ e^{-y^2+1} = 2,\quad t>1,\\
    y(1) &= -1.
  \end{align}
Use os seguintes métodos de Runge-Kutta com passo $h=0,1$ para computar o valor aproximado de $y(2)$:
\begin{enumerate}[a)]
\item método do ponto médio.
\item método de Euler modificado.
\item método de Runge-Kutta de ordem $4$.
\end{enumerate}
\end{exer}
\begin{resp}
  % \ifisoctave 
  % \href{https://github.com/phkonzen/notas/blob/master/src/MatematicaNumerica/cap_pvi/dados/exer_RK_pvi1/exer_RK_pvi1.m}{Código.} 
  % \fi
  a)~$-6,00654\E-1$; b)~$-6,00703\E-1$; c)~$-5,99608\E-1$
\end{resp}

\section{Método adaptativo com controle de erro}\label{cap_pvi_met_adap}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Consideremos um problema de valor inicia
\begin{align}
  y'(t) &= f(t,y(t)),\quad t>t_0,\\
  y(t_0) &= y_0.
\end{align}
e um método de passo simples
\begin{align}
  y^{(1)} &= y_0,\\
  y^{(i+1)}(h^{(i+1)}) &= y^{(i)} + h^{(i+1)}\Phi(t^{(i)},y^{(i)};h^{(i+1)}),
\end{align}
com $t^{(i)} = t_0 + (i-1)h^{(i)}$. Nesta seção, discutiremos uma estimava para o maior valor de $h^{(i+1)}$ tal que o erro de discretização global $e(t^{(i+1)};h^{(i+1)})$ seja controlado por uma dada tolerância $TOL$, i.e.
\begin{equation}\label{eq:pvi_erro_aux1}
  |e(t^{(i+1)};h^{(i+1)})| := |y^{(i+1)}(h^{(i+1)}) - y(t^{(i+1)})| \approx TOL.
\end{equation}

Para um método de ordem $h^p$, pode-se mostrar que (veja, \cite[Cap. 7, Seç. 7.2]{Isaacson1994a})
\begin{equation}\label{eq:pvi_erro_aux0}
  y^{(i+1)}(h^{(i+1)}) = y(t^{(i+1)}) + e_p(t^{(i+1)})(h^{(i+1)})^p,
\end{equation}
onde $e(t^{(i+1)})$ é uma função apropriada. Então, assumindo que $e(t^{(i)};h^{(i)})=0$, temos
\begin{equation}\label{eq:pvi_erro_aux2}
  e_p(t^{(i+1)}) = h^{(i+1)}e_p'(t^{(i)})
\end{equation}
e, portanto, para termos \eqref{eq:pvi_erro_aux1} impomos que
\begin{equation}\label{eq:pvi_erro_aux4}
  |(h^{(i+1)})^{p+1}e_p'(t^{(i)})| = TOL.
\end{equation}
Daí, se obtermos uma aproximação para $e_p'(t^{(i)})$ teremos uma aproximação para o passo $h^{(i+1)}$.

Para estimarmos $e_p(t^{(i+1)})$, observamos que de \eqref{eq:pvi_erro_aux0} temos
\begin{equation}
  y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right) = y(t^{(i+1)}) + e_p(t^{(i+1)})\frac{(h^{(i+1)})^p}{2^p}
\end{equation}
e, então, subtraindo esta de \eqref{eq:pvi_erro_aux0} temos
\begin{equation}
  y^{(i+1)}(h^{(i+1)}) - y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right) = e_p(t^{(i+1)})\left(\frac{h^{(i+1)}}{2}\right)^p(2^p-1),
\end{equation}
donde
\begin{equation}
  e_p(t^{(i+1)})\left(\frac{h^{(i+1)}}{2}\right)^p = \frac{y^{(i+1)}(h^{(i+1)}) - y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right)}{2^p-1}.
\end{equation}
Daí, de \eqref{eq:pvi_erro_aux2}, obtemos
\begin{equation}
  e_p'(t^{(i)})h^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right)^p = \frac{y^{(i+1)}(h^{(i+1)}) - y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right)}{2^p-1},
\end{equation}
o que nos fornece a seguinte aproximação de $e_p'(t^{(i)})$
\begin{equation}
  e_p'(t^{(i)}) = \frac{1}{(h^{(i+1)})^{p+1}}\frac{2^p}{2^p-1}\left[y^{(i+1)}(h^{(i+1)}) - y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right)\right].
\end{equation}

Assim sendo, de \eqref{eq:pvi_erro_aux4} temos que o passo $h^{(i+1)}$ apropriado é tal que
\begin{equation}\label{eq:pvi_passo_est}
  \frac{2^p}{2^p-1}\left|y^{(i+1)}(h^{(i+1)}) - y^{(i+1)}\left(\frac{h^{(i+1)}}{2}\right)\right| \approx TOL.
\end{equation}

Com base nesta estimativa podemos propor o seguinte método de passo adaptativo. Partindo de uma escolha arbitrária de $h$, computamos $y^{(i+1)}(h)$ e $y^{(i+1)}(h/2)$ de  $y^{(i)}$. Então, enquanto
\begin{equation}
  \frac{2^p}{2^p-1}\left|y^{(i+1)}(h) - y^{(i+1)}\left(\frac{h}{2}\right)\right| > TOL,
\end{equation}
tomamos sucessivas divisões de $h$ por $2$, até satisfazermos \eqref{eq:pvi_passo_est}. Obtido o $h$ que satisfaz \eqref{eq:pvi_passo_est}, temos computado $y^{(i+1)}$ com $h^{(i+1)}=h$.

\begin{ex}\label{ex:Euler_adap}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  A Figura~\ref{fig:ex_Euler_adap} mostra a comparação entre $y(t)$ e a solução numérica obtida da aplicação do método de Euler com passo adaptativo. No método, utilizamos o passo inicial $h^{(1)}=0,1$ e tolerância $TOL=10^{-4}$. Ao compararmos esta figura com a Figura~\eqref{fig:ex_Euler_1} fica evidente o controle do erro.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{./cap_pvi/dados/ex_Euler_adap/ex_Euler_adap}
    \caption{Resultados referentes ao Exemplo~\ref{ex:Euler_adap}.}
    \label{fig:ex_Euler_adap}
  \end{figure}

% \ifisoctave
% O algoritmo utilizado neste exemplo pode ser implementado no \verb+GNU Octave+ com o seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% TOL=1e-4;
% h=1e-1;
% tf=1;

% t0=0;
% y0=0.5;

% t=[];
% y=[];

% c=1;
% do

%   h = min(h,tf-t0);
 
%   do
%     #passo h
%     y1=y0+h*f(t0,y0);
%     #passo h/2
%     y2=y0+h/2*f(t0,y0);
%     y2=y2+h/2*f(t0+h/2,y2);
%     #verifica TOL
%     est = 2*abs(y1-y2);
%     if (est > TOL)
%       h/=2;
%       if (h<1e-8)
%         error("h muito pequeno")
%       endif
%     else
%       t0+=h;
%       y0=y2;
      
%       t(c)=t0;
%       y(c)=y0;
%       c+=1;
%     endif
%   until ((est <= TOL))
  
% until (abs(t0-tf)<1e-14)

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%1.1E %1.5E %1.1E\n",t0,y0,abs(y0-ya(1)))

% plot(t,ya(t),'b-',t,y,'r-');grid
% \end{verbatim}
% \fi

\end{ex}

\subsection{Exercícios}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

\begin{exer}
  Considere o seguinte problema de valor inicial
  \begin{align}
    y' &+ e^{-y^2+1} = 2,\quad t>1,\\
    y(1) &= -1.
  \end{align}
Use o método de Euler com passo adaptativo para computar o valor aproximado de $y(2)$. Para tanto, utilize o passo inicial $h=0,1$ e a tolerância de $TOL=10^{-4}$.
\end{exer}
\begin{resp}
  % \ifisoctave 
  % \href{https://github.com/phkonzen/notas/blob/master/src/MatematicaNumerica/cap_pvi/dados/exer_Euler_adap/exer_Euler_adap.m}{Código.} 
  % \fi
  $-5.99240\E-1$
\end{resp}


\section{Métodos de passo múltiplo}\label{cap_pvi_sec_passo_mult}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Dado um problema de valor inicial
\begin{align}
  y'(t) &= f(t,y(t)),\quad t>t_0,\\
  y(t_0) &= y_0.
\end{align}
temos
\begin{equation}
  y(t) = y(t_0) + \int_{t_0}^t f(s,y(s))\,ds.
\end{equation}
De forma mais geral, consideramos uma partição uniforme no tempo $\{t_0=t^{(1)} < t^{(2)} < \cdots < t^{(i)} < \cdots < t^{(n)}=t_f\}$, onde $t_f$ é um determinado tempo para o qual queremos computar uma aproximação para $y(t_f)$. Também, denotamos o passo no tempo por $h=(t_f-t_0)/n$. Com isso, a solução $y(t)$ satisfaz
\begin{equation}
  y\left(t^{(i+k)}\right) = y\left(t^{(i-j)}\right) + \int_{t^{(i-j)}}^{t^{(i+k)}} f(s,y(s))\,ds.
\end{equation}
A ideia é, então, aproximar a integral acima por uma quadratura numérica.

Seguindo as regras de Newton-Cotes (veja, Cap.~\ref{cap_integr} Seç.~\ref{cap_integr_sec_NC}), escolhemos os nodos da quadratura como $x_l = t^{(i-l+1)}$, $l = 1, 2, \dotsc, m$, e, então
\begin{equation}
  \int_{t^{(i-j)}}^{t^{i+k}} f(x,y(x))\,dx \approx \sum_{l=1}^{m} f\left(x_l,y(x_l)\right)w_l,
\end{equation}
e
\begin{equation}
  w_l = \int_{t^{(i-j)}}^{t^{(i+k)}} \prod_{\overset{p=1}{p\neq l}}^m \frac{x-x_p}{x_l-x_p}\,dx.
\end{equation}
Agora, fazendo a mudança de variável $u=(x-t^{(i)})/h$, obtemos
\begin{equation}
  w_l = h\int_{-j}^{k} \prod_{\overset{p=1}{p\neq l}}^m \frac{u+p-1}{-l+p}\,du
\end{equation}
Assim sendo, temos o seguinte esquema numérico
\begin{equation}
  y^{(i+k)} = y^{(i-j)} + h\sum_{l=1}^m c_{l}f(t^{(i-l+1)},y^{(i-l+1)}),\label{eq:mult_passo_iter}
\end{equation}
onde
\begin{equation}
  c_l = \int_{-j}^{k} \prod_{\overset{p=1}{p\neq l}}^m \frac{s+p-1}{-l+p}\,ds.\label{eq:mult_passo_pesos}
\end{equation}

Diferentes escolhas de $j$, $k$ e $m$ não fornecem diferentes métodos. Observamos, ainda, que a ordem de um tal método de passo múltiplo é determinada pela ordem de truncamento da quadratura numérica usada (veja, por exemplo, \cite[Cap. 5, Seç. 5.6]{Burden2015a}).

\subsection{Métodos de Adams-Bashforth}\index{método de Adams-Bashforth}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Métodos de Adams-Bashforth são métodos de passo múltiplo obtidos ao escolhermos $j=0$ e $k=1$ no esquema numérico~\eqref{eq:mult_passo_iter}. Com isso, ao escolhermos $m$ obtemos um método de ordem $O(h^{m})$~\cite[Cap. 5, Seç. 5.6]{Burden2015a}.

\subsubsection{Método de Adams-Bashforth de ordem 2}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Tomando $m=2$ em \eqref{eq:mult_passo_pesos}, temos
\begin{equation}
  c_1 = \int_0^1 s+1\,ds = \frac{3}{2}
\end{equation}
e
\begin{equation}
  c_2 = \int_0^1 -s\,ds = -\frac{1}{2}.
\end{equation}
Então, de \eqref{eq:mult_passo_iter} temos a iteração do \emph{método de Adams-Bashforth de $2$ passos}:
\begin{align}
  y^{(1)} &= y_0,\\
  y^{(i+1)} &= y^{(i)} + \frac{h}{2}\left[3f(t^{(i)},y^{(i)}) - f(t^{(i-1)},y^{(i-1)})\right],
\end{align}
com $t^{(i)} = t_0 + (i-1)h$.

\begin{ex}\label{ex:AB2}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_AB2}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método de Adams-Bashforth de $2$ passos. Como este método é de ordem $2$, escolhemos inicializá-lo pelo método do ponto médio, de forma a mantermos a consistência.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,01582$ & $1,2\E-02$ \\
      $10^{-2}$ & $2,02727$ & $1,3\E-04$ \\
      $10^{-3}$ & $2,02739$ & $1,3\E-06$ \\
      $10^{-4}$ & $2,02740$ & $1,3\E-08$ \\
      $10^{-5}$ & $2,02740$ & $1,3\E-10$ \\\hline
    \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:AB2}}
    \label{tab:ex_AB2}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_AB2} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-1;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% #c.i.
% t(1)=0;
% y(1)=0.5;

% #inicializacao
% t(2)=t(1)+h;
% y(2)=y(1)+h*f(t(1)+h/2,y(1)+h/2*f(t(1),y(1)));

% #iteracoes
% for i=2:n-1
%   t(i+1) = t(i)+h;
%   y(i+1)=y(i) + ...
%         h/2*(3*f(t(i),y(i))-f(t(i-1),y(i-1)));
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%f %1.5E %1.1E\n",t(n),y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsubsection{Método de Adams-Bashforth de ordem 3}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Tomando $m=3$ em \eqref{eq:mult_passo_pesos} obtemos, de \eqref{eq:mult_passo_iter}, a iteração do \emph{método de Adams-Bashforth de $3$ passos}:
\begin{align}
  y^{(1)} &= y_0,\\
  y^{(i+1)} &= y^{(i)} + \frac{h}{12}\left[23f(t^{(i)},y^{(i)}) \right.\nonumber\\
              &\left. - 16f(t^{(i-1)},y^{(i-1)}) + 5f(t^{(i-2)},y^{(i-2)})\right],
\end{align}
com $t^{(i)} = t_0 + (i-1)h$.

\begin{ex}\label{ex:AB3}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_AB3}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método de Adams-Bashforth de $3$ passos. Como este método é de ordem $3$, escolhemos inicializá-lo pelo método de Runge-Kutta de ordem $4$, de forma a garantirmos a consistência.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,02696$ & $4,3\E-04$ \\
      $10^{-2}$ & $2,02739$ & $5,9\E-07$ \\
      $10^{-3}$ & $2,02740$ & $6,1\E-10$ \\
      $10^{-4}$ & $2,02740$ & $6,6\E-13$ \\\hline
   \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:AB3}}
    \label{tab:ex_AB3}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_AB3} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-1;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% #c.i.
% t(1)=0;
% y(1)=0.5;

% #inicializacao
% for i=1:2
%   t(i+1)=t(i)+h;
%   k1=h*f(t(i),y(i));
%   k2=h*f(t(i)+h/2,y(i)+k1/2);
%   k3=h*f(t(i)+h/2,y(i)+k2/2);
%   k4=h*f(t(i)+h,y(i)+k3);
%   y(i+1)=y(i)+(k1+2*k2+2*k3+k4)/6;
% endfor

% #iteracoes
% for i=3:n-1
%   t(i+1) = t(i)+h;
%   y(i+1)=y(i) + ...
%         h/12*(23*f(t(i),y(i)) ...
%         -16*f(t(i-1),y(i-1)) ...
%         +5*f(t(i-2),y(i-2)));
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%f %1.5E %1.1E\n",t(n),y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsubsection{Método de Adams-Bashforth de ordem 4}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

Tomando $m=4$ em \eqref{eq:mult_passo_pesos} obtemos, de \eqref{eq:mult_passo_iter}, a iteração do \emph{método de Adams-Bashforth de $4$ passos}:
\begin{align}
  y^{(1)} &= y_0,\\
  y^{(i+1)} &= y^{(i)} + \frac{h}{24}\left[55f(t^{(i)},y^{(i)}) \right.\nonumber\\
              &\left. - 59f(t^{(i-1)},y^{(i-1)}) + 37f(t^{(i-2)},y^{(i-2)}) \right. \nonumber \\
          &\left. -9f(t^{(i-3)},y^{(i-3)})\right],
\end{align}
com $t^{(i)} = t_0 + (i-1)h$.

\begin{ex}\label{ex:AB4}
  Consideremos o seguinte problema de valor inicial
  \begin{align}
    y' - y &= \sen(t), t>0\\
    y(0) &= \frac{1}{2}.
  \end{align}
  Na Tabela~\ref{tab:ex_AB4}, temos as aproximações $\tilde{y}(1)$ de $y(1)$ computadas pelo método de Adams-Bashforth de $4$ passos. Como este método é de ordem $3$, escolhemos inicializá-lo pelo método de Runge-Kutta de ordem $4$, de forma a mantermos a consistência.
 
  \begin{table}[h!]
    \centering
    \begin{tabular}{l|cc}
      $h$ & $\tilde{y}(1)$ & $|\tilde{y}(1)-y(1)|$\\\hline
      $10^{-1}$ & $2,02735$ & $5,0\E-05$ \\
      $10^{-2}$ & $2,02740$ & $7,7\E-09$ \\
      $10^{-3}$ & $2,02740$ & $7,9\E-13$ \\\hline
   \end{tabular}
    \caption{Resultados referentes ao Exemplo~\ref{ex:AB4}}
    \label{tab:ex_AB4}
  \end{table}

% \ifisoctave
% Os resultados mostrados na Tabela~\ref{tab:ex_AB4} podem ser computados no \verb+GNU Octave+ com o auxílio do seguinte código:
% \begin{verbatim}
% f = @(t,y) y+sin(t);

% h=1e-1;
% n=round(1/h+1);
% t=zeros(n,1);
% y=zeros(n,1);

% #c.i.
% t(1)=0;
% y(1)=0.5;

% #inicializacao
% for i=1:3
%   t(i+1)=t(i)+h;
%   k1=h*f(t(i),y(i));
%   k2=h*f(t(i)+h/2,y(i)+k1/2);
%   k3=h*f(t(i)+h/2,y(i)+k2/2);
%   k4=h*f(t(i)+h,y(i)+k3);
%   y(i+1)=y(i)+(k1+2*k2+2*k3+k4)/6;
% endfor

% #iteracoes
% for i=4:n-1
%   t(i+1) = t(i)+h;
%   y(i+1)=y(i) + ...
%         h/24*(55*f(t(i),y(i)) ...
%         -59*f(t(i-1),y(i-1)) ...
%         +37*f(t(i-2),y(i-2)) ...
%         -9*f(t(i-3),y(i-3)));
% endfor

% ya = @(t) exp(t)-sin(t)/2-cos(t)/2;
% printf("%f %1.5E %1.1E\n",t(n),y(n),abs(y(n)-ya(1)))
% \end{verbatim}
% \fi
\end{ex}

\subsection{Exercícios}

\begin{flushleft}
  [[tag:revisar]]
\end{flushleft}

\begin{exer}
  Considere o seguinte problema de valor inicial
  \begin{align}
    y' &+ e^{-y^2+1} = 2,\quad t>1,\\
    y(1) &= -1.
  \end{align}
Inicializando pelo método de Euler, use os seguintes métodos de passo múltiplo com $h=0,1$ para computar o valor aproximado de $y(2)$:
\begin{enumerate}[a)]
\item método de Adams-Bashforth de ordem $2$.
\item método de Adams-Bashforth de ordem $3$.
\item método de Adams-Bashforth de ordem $4$.
\end{enumerate}
\end{exer}
\begin{resp}
  % \ifisoctave 
  % \href{https://github.com/phkonzen/notas/blob/master/src/MatematicaNumerica/cap_pvi/dados/exer_AB_pvi1/exer_AB_pvi1.m}{Código.} 
  % \fi
  a)~$-6,00696\E-1$; b)~$-5,96694\E-1$; c)~$-5,96161\E-1$
\end{resp}
